{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "349c1ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c3e8478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "points1=torch.tensor([[1.0,2.0],[3.0,4.0],[5.0,7.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb3c1428",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_storage1=points1.storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be28a741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LOQ\\AppData\\Local\\Temp\\ipykernel_6320\\3775807201.py:2: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  points_storage = points.storage()\n"
     ]
    }
   ],
   "source": [
    "points = torch.tensor([[1.0, 4.0], [2.0, 1.0], [3.0, 5.0]])\n",
    "points_storage = points.storage()\n",
    "points_storage[0] = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd294693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 4.],\n",
       "        [2., 1.],\n",
       "        [3., 5.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ac90559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[1.0, 4.0], [2.0, 1.0], [3.0, 5.0]])\n",
    "second_points=points[1]\n",
    "second_points.storage_offset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8962f371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_points.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "387ba272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f9a9cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  4.],\n",
       "        [10.,  1.],\n",
       "        [ 3.,  5.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[1.0, 4.0], [2.0, 1.0], [3.0, 5.0]])\n",
    "second_points=points[1]\n",
    "second_points[0]=10.0\n",
    "points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5144b596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4.],\n",
       "        [2., 1.],\n",
       "        [3., 5.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[1.0, 4.0], [2.0, 1.0], [3.0, 5.0]])\n",
    "second_points1=points[1].clone()\n",
    "second_points1[0]=10.0\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5e05d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 1., 5.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transpose\n",
    "points = torch.tensor([[1.0, 4.0], [2.0, 1.0], [3.0, 5.0]])\n",
    "points_t=points.t()\n",
    "points_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51583ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numeric types\n",
    "double_points=torch.ones(10,2, dtype=torch.double)\n",
    "double_points.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "699cf8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexing tensor\n",
    "some_list=list(range(5))\n",
    "some_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d057377b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list[:]\n",
    "some_list[1:4]\n",
    "some_list[:4]\n",
    "some_list[:3]\n",
    "some_list[1:4:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22fd8e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy interoprability\n",
    "\n",
    "points=torch.ones(3,4)\n",
    "points_np=points.numpy()\n",
    "points_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "448c0a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "wine_path=\"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5c25845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning is the estimation\n",
    "\n",
    "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0]\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38b0778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(t_u ,w,b):\n",
    "    return w*t_u +b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3de38a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(t_p,t_c):\n",
    "    squared_difference=(t_p-t_c)**2\n",
    "    return squared_difference.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c988d56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w=torch.ones(1)\n",
    "b=torch.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f7fe28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_p=model(t_u ,w,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4fb4d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([35.7000, 55.9000, 58.2000, 81.9000, 56.3000, 48.9000, 33.9000, 21.8000,\n",
       "        48.4000, 60.4000, 68.4000])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "656411e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d9311e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autograd in pytorch\n",
    "\n",
    "x=torch.tensor(3.0 , requires_grad=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a5df29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3., requires_grad=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6438fce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e79de537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d386bbff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81479124",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor(3.0, requires_grad=True)\n",
    "y=x**2\n",
    "z=torch.sin(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8ca17779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4121, grad_fn=<SinBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ebb2a3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-5.4668)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68fb610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using autograd calculate loss\n",
    "\n",
    "x=torch.tensor(6.7)\n",
    "y=torch.tensor(0.0)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0fe8f835",
   "metadata": {},
   "outputs": [],
   "source": [
    "w=torch.tensor(1.0 ,requires_grad=True)\n",
    "b=torch.tensor(0.0 , requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8bfc2d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=w*x+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ef160576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.7000, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "69305bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9988, grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=torch.sigmoid(z)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "580dedd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.7012, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss1 = F.binary_cross_entropy(y_pred, y)\n",
    "loss1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "44dafbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3e716210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., requires_grad=True)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clearing grad\n",
    "x=torch.tensor(2.0 , requires_grad=True)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "93d9eece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=x**2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "456cc9c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[76]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LOQ\\Desktop\\adavance_pytohn\\env2\\Lib\\site-packages\\torch\\_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LOQ\\Desktop\\adavance_pytohn\\env2\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LOQ\\Desktop\\adavance_pytohn\\env2\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "17892042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0a487b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2 (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
